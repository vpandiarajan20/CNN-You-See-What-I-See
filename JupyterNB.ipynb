{"cells":[{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Downloading dataset to 'C:\\Users\\vpand\\fiftyone\\imagenet-sample'\n","Downloading dataset...\n"," 100% |████|  762.4Mb/762.4Mb [5.9s elapsed, 0s remaining, 133.6Mb/s]      \n","Extracting dataset...\n","Parsing dataset metadata\n","Found 1000 samples\n","Dataset info written to 'C:\\Users\\vpand\\fiftyone\\imagenet-sample\\info.json'\n","Loading 'imagenet-sample'\n"," 100% |███████████████| 1000/1000 [650.7ms elapsed, 0s remaining, 1.5K samples/s]      \n","Dataset 'imagenet-sample' created\n"]},{"data":{"text/html":["\n","        <iframe\n","            width=\"100%\"\n","            height=\"800\"\n","            src=\"http://localhost:5151/?notebook=true&handleId=6df5c217-48ef-4bf6-a3b4-52f83e0c94a0\"\n","            frameborder=\"0\"\n","            allowfullscreen\n","            \n","        ></iframe>\n","        "],"text/plain":["<IPython.lib.display.IFrame at 0x1f9433be1c0>"]},"metadata":{},"output_type":"display_data"}],"source":["!git clone https://github.com/tensorflow/tcav.git tcav\n","%cd tcav\n","!ls"]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[{"ename":"FileNotFoundError","evalue":"[WinError 2] The system cannot find the file specified","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[1;32mc:\\Users\\vpand\\Documents\\College\\Fall 2021\\CNN-You-See-What-I-See\\tcav\\tcav\\tcav_examples\\image_models\\imagenet\\download_and_make_datasets.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     88\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Created source directory at \"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msource_dir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m     \u001b[1;31m# Make data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 90\u001b[1;33m     \u001b[0mmake_concepts_targets_and_randoms\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msource_dir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumber_of_images_per_folder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumber_of_random_folders\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     91\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Successfully created data at \"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msource_dir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32mc:\\Users\\vpand\\Documents\\College\\Fall 2021\\CNN-You-See-What-I-See\\tcav\\tcav\\tcav_examples\\image_models\\imagenet\\download_and_make_datasets.py\u001b[0m in \u001b[0;36mmake_concepts_targets_and_randoms\u001b[1;34m(source_dir, number_of_images_per_folder, number_of_random_folders)\u001b[0m\n\u001b[0;32m     44\u001b[0m         \u001b[0mgfile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msource_dir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mgfile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msource_dir\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'broden1_224/'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mgfile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msource_dir\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'inception5h'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 46\u001b[1;33m         \u001b[0msubprocess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'bash'\u001b[0m \u001b[1;33m,\u001b[0m \u001b[1;34m'FetchDataAndModels.sh'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msource_dir\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     47\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m     \u001b[1;31m# Determine classes that we will fetch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\subprocess.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(timeout, *popenargs, **kwargs)\u001b[0m\n\u001b[0;32m    338\u001b[0m     \u001b[0mretcode\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"ls\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"-l\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    339\u001b[0m     \"\"\"\n\u001b[1;32m--> 340\u001b[1;33m     \u001b[1;32mwith\u001b[0m \u001b[0mPopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mpopenargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    341\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    342\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\subprocess.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, encoding, errors, text)\u001b[0m\n\u001b[0;32m    856\u001b[0m                             encoding=encoding, errors=errors)\n\u001b[0;32m    857\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 858\u001b[1;33m             self._execute_child(args, executable, preexec_fn, close_fds,\n\u001b[0m\u001b[0;32m    859\u001b[0m                                 \u001b[0mpass_fds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcwd\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0menv\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    860\u001b[0m                                 \u001b[0mstartupinfo\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreationflags\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshell\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\subprocess.py\u001b[0m in \u001b[0;36m_execute_child\u001b[1;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, unused_restore_signals, unused_start_new_session)\u001b[0m\n\u001b[0;32m   1309\u001b[0m             \u001b[1;31m# Start the process\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1310\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1311\u001b[1;33m                 hp, ht, pid, tid = _winapi.CreateProcess(executable, args,\n\u001b[0m\u001b[0;32m   1312\u001b[0m                                          \u001b[1;31m# no special security\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1313\u001b[0m                                          \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 2] The system cannot find the file specified"]}],"source":["# %pwd\n","%cd tcav_examples/image_models/imagenet \n","%run download_and_make_datasets.py --source_dir=YOUR_FOLDER --number_of_images_per_folder=10 --number_of_random_folders=10"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["tf.Tensor(\n","[[1. 0.]\n"," [1. 0.]\n"," [1. 0.]\n"," ...\n"," [1. 0.]\n"," [1. 0.]\n"," [0. 1.]], shape=(10000, 2), dtype=float32)\n"]}],"source":["import tcav.activation_generator as act_gen\n","import tcav.cav as cav\n","import tcav.model  as model\n","import tcav.tcav as tcav\n","import tcav.utils as utils\n","import tcav.utils_plot as utils_plot # utils_plot requires matplotlib\n","import os \n","import tensorflow as tf"]},{"cell_type":"code","execution_count":27,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["(0,)\n","[]\n"]}],"source":["# This is the name of your model wrapper (InceptionV3 and GoogleNet are provided in model.py)\n","model_to_run = 'GoogleNet'\n","# the name of the parent directory that results are stored (only if you want to cache)\n","project_name = 'tcav_class_test'\n","working_dir = '/content/tcav/tcav'\n","# where activations are stored (only if your act_gen_wrapper does so)\n","activation_dir =  working_dir+ '/activations/'\n","# where CAVs are stored. \n","# You can say None if you don't wish to store any.\n","cav_dir = working_dir + '/cavs/'\n","# where the images live. \n","source_dir = '/content/tcav/tcav/tcav_examples/image_models/imagenet/YOUR_FOLDER'\n","bottlenecks = [ 'mixed4c']  # @param \n","      \n","utils.make_dir_if_not_exists(activation_dir)\n","utils.make_dir_if_not_exists(working_dir)\n","utils.make_dir_if_not_exists(cav_dir)\n","\n","# this is a regularizer penalty parameter for linear classifier to get CAVs. \n","alphas = [0.1]   \n","\n","target = 'zebra'  \n","concepts = [\"dotted\",\"striped\",\"zigzagged\"]   "]},{"cell_type":"code","execution_count":28,"metadata":{},"outputs":[],"source":["unpickled_file = unpickle(r\"C:\\Users\\vpand\\Documents\\College\\Fall 2021\\CS1470 HW\\hw2-cnn-vpandiarajan20\\data\\train\")\n","inputs = unpickled_file[b'data']\n","labels = unpickled_file[b'labels']\n","labels_coords = np.nonzero((labels == 3) | (labels == 5))\n","labels = labels[labels_coords];\n","inputs = inputs[labels_coords] / 255;\n","inputs = tf.reshape(inputs, (-1, 3, 32 ,32))\n","inputs = tf.transpose(inputs, perm=[0,2,3,1])\n","labels = np.where(labels == 3, 0, 1)\n","o_hot_labels = tf.one_hot(labels, 2)\n"]},{"cell_type":"code","execution_count":57,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["tf.Tensor([64 32 32  3], shape=(4,), dtype=int32)\n","tf.Tensor([64 28 28 16], shape=(4,), dtype=int32)\n","tf.Tensor([64 14 14 16], shape=(4,), dtype=int32)\n","tf.Tensor([64  7  7 20], shape=(4,), dtype=int32)\n","tf.Tensor([64  4  4 20], shape=(4,), dtype=int32)\n","tf.Tensor([64  4  4 20], shape=(4,), dtype=int32)\n","tf.Tensor([64  4  4 20], shape=(4,), dtype=int32)\n"]}],"source":["inputs = inputs[0:64]\n","print(tf.shape(inputs))\n","filters_1 = tf.Variable(tf.random.truncated_normal([5,5,3,16], stddev=.1, dtype=tf.double))\n","conv_1 = tf.nn.conv2d(inputs, filters_1, strides=[1, 1, 1, 1], padding='VALID')\n","print(tf.shape(conv_1))\n","mean_1, variance_1 = tf.nn.moments(conv_1, [0,1,2])\n","batch_normalize_1 = tf.nn.batch_normalization(conv_1, mean_1, variance_1, None, None, variance_epsilon=1e-5)\n","post_relu_1 = tf.nn.relu(batch_normalize_1)\n","post_max_pooling_1 = tf.nn.max_pool(post_relu_1, ksize=[1,3,3,1], strides=[1,2,2,1], padding='SAME')\n","print(tf.shape(post_max_pooling_1))\n","\n","filters_2 = tf.Variable(tf.random.truncated_normal([5,5,16,20], stddev=.1, dtype=tf.double))        \n","conv_2 = tf.nn.conv2d(post_max_pooling_1, filters_2, strides=[1, 2, 2, 1], padding='SAME')\n","print(tf.shape(conv_2))\n","mean_2, variance_2 = tf.nn.moments(conv_2, [0,1,2])\n","batch_normalize_2 = tf.nn.batch_normalization(conv_2, mean_2, variance_2, None, None, variance_epsilon=1e-5)\n","post_relu_2 = tf.nn.relu(batch_normalize_2)\n","post_max_pooling_2 = tf.nn.max_pool(post_relu_2, ksize=[1,2,2,1], strides=[1,2,2,1], padding=\"SAME\")\n","print(tf.shape(post_max_pooling_2))\n","\n","filters_3 = tf.Variable(tf.random.truncated_normal([3,3,20,20], stddev=.1, dtype=tf.double))\n","conv_3 = tf.nn.conv2d(post_max_pooling_2, filters_3, strides=[1,1,1,1], padding=\"SAME\")\n","print(tf.shape(conv_3))\n","mean_3, variance_3 = tf.nn.moments(conv_3, [0,1,2])\n","batch_normalize_3 = tf.nn.batch_normalization(conv_3, mean_3, variance_3, None, None, variance_epsilon=1e-5)\n","post_relu_3 = tf.nn.relu(batch_normalize_3)\n","print(tf.shape(post_relu_3))\n","\n"]},{"cell_type":"code","execution_count":38,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["tf.Tensor(8555, shape=(), dtype=int32)\n"]}],"source":["rank_3_tensor = tf.constant([\n","  [[0, 1, 2, 3, 4],\n","   [5, 6, 7, 8, 9]],\n","  [[10, 11, 12, 13, 14],\n","   [15, 16, 17, 18, 19]],\n","  [[20, 21, 22, 23, 24],\n","   [25, 26, 27, 28, 29]],])\n","\n","print(tf.tensordot(rank_3_tensor, rank_3_tensor, axes = 3))"]},{"cell_type":"code","execution_count":55,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["[[[75. 75. 75. ... 75. 75. 75.]\n","  [ 0.  0.  0. ...  0.  0.  0.]\n","  [ 0.  0.  0. ...  0.  0.  0.]\n","  ...\n","  [ 0.  0.  0. ...  0.  0.  0.]\n","  [ 0.  0.  0. ...  0.  0.  0.]\n","  [ 0.  0.  0. ...  0.  0.  0.]]\n","\n"," [[ 0.  0.  0. ...  0.  0.  0.]\n","  [ 0.  0.  0. ...  0.  0.  0.]\n","  [ 0.  0.  0. ...  0.  0.  0.]\n","  ...\n","  [ 0.  0.  0. ...  0.  0.  0.]\n","  [ 0.  0.  0. ...  0.  0.  0.]\n","  [ 0.  0.  0. ...  0.  0.  0.]]\n","\n"," [[ 0.  0.  0. ...  0.  0.  0.]\n","  [ 0.  0.  0. ...  0.  0.  0.]\n","  [ 0.  0.  0. ...  0.  0.  0.]\n","  ...\n","  [ 0.  0.  0. ...  0.  0.  0.]\n","  [ 0.  0.  0. ...  0.  0.  0.]\n","  [ 0.  0.  0. ...  0.  0.  0.]]\n","\n"," ...\n","\n"," [[ 0.  0.  0. ...  0.  0.  0.]\n","  [ 0.  0.  0. ...  0.  0.  0.]\n","  [ 0.  0.  0. ...  0.  0.  0.]\n","  ...\n","  [ 0.  0.  0. ...  0.  0.  0.]\n","  [ 0.  0.  0. ...  0.  0.  0.]\n","  [ 0.  0.  0. ...  0.  0.  0.]]\n","\n"," [[ 0.  0.  0. ...  0.  0.  0.]\n","  [ 0.  0.  0. ...  0.  0.  0.]\n","  [ 0.  0.  0. ...  0.  0.  0.]\n","  ...\n","  [ 0.  0.  0. ...  0.  0.  0.]\n","  [ 0.  0.  0. ...  0.  0.  0.]\n","  [ 0.  0.  0. ...  0.  0.  0.]]\n","\n"," [[ 0.  0.  0. ...  0.  0.  0.]\n","  [ 0.  0.  0. ...  0.  0.  0.]\n","  [ 0.  0.  0. ...  0.  0.  0.]\n","  ...\n","  [ 0.  0.  0. ...  0.  0.  0.]\n","  [ 0.  0.  0. ...  0.  0.  0.]\n","  [ 0.  0.  0. ...  0.  0.  0.]]]\n"]}],"source":["inputImage = tf.ones([64, 5, 5, 3])\n","inputFilters = tf.ones([5, 5, 3, 16])\n","# print(tf.tensordot(inputImage, inputFilters, ([1,2,3], [0, 1, 2])))\n","outputs = np.zeros((64, 32, 32, 16))\n","tensorOut = tf.tensordot(inputImage, inputFilters, ([1,2,3], [0, 1, 2]))\n","outputs[:, 0, 0, :] = tensorOut\n","print(outputs[0, :, :, :])"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":75,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["[64 32 32  3]\n","[ 5  5  3 16]\n","16\n","<class 'int'>\n","2241.5220263007527\n"]}],"source":["import math\n","def conv2d(inputs, filters, strides, padding):\n","\t\"\"\"\n","\tPerforms 2D convolution given 4D inputs and filter Tensors.\n","\t:param inputs: tensor with shape [num_examples, in_height, in_width, in_channels]\n","\t:param filters: tensor with shape [filter_height, filter_width, in_channels, out_channels]\n","\t:param strides: MUST BE [1, 1, 1, 1] - list of strides, with each stride corresponding to each dimension in input\n","\t:param padding: either \"SAME\" or \"VALID\", capitalization matters\n","\t:return: outputs, NumPy array or Tensor with shape [num_examples, output_height, output_width, output_channels]\n","\t\"\"\"\n","\tinputs_shapes = tf.shape(inputs)\n","\tinputs_shapes = np.array(inputs_shapes)\n","\tprint(inputs_shapes)\n","\n","\tnum_examples = inputs_shapes[0]\n","\tin_height = inputs_shapes[1]\n","\tin_width = inputs_shapes[2]\n","\tinput_in_channels = inputs_shapes[3]\n","\t\n","\tfilter_shapes = tf.shape(filters)\n","\tfilter_shapes = np.array(filter_shapes)\n","\tprint(np.array(filter_shapes))\n","\t\n","\n","\tfilter_height = filter_shapes[0]\n","\tfilter_width = filter_shapes[1]\n","\tfilter_in_channels = filter_shapes[2]\n","\tfilter_out_channels = filter_shapes[3]\n","\n","\tprint(filter_out_channels)\n","\n","\tstrides = np.array(strides)\n","\n","\tnum_examples_stride = strides[0]\n","\tstrideY = strides[1]\n","\tstrideX = strides[2]\n","\tchannels_stride = strides[3]\n","\n","\tassert input_in_channels == filter_in_channels, \"input in channels are not equal to filter in channels\"\n","\n","\t# Cleaning padding input\n","\tif padding == \"SAME\":\n","\t\tpadX = math.floor((filter_height-1)/2)\n","\t\tpadY = math.floor((filter_height-1)/2)\n","\telse:\n","\t\tpadX = 0\n","\t\tpadY = 0\n","\t# Calculate output dimensions\n","\toutput_height = math.floor(((in_height + 2*padY - filter_height) / strideY + 1))\n","\toutput_width = math.floor(((in_width + 2*padX - filter_width) / strideX + 1))\n","\tprint(type(output_height))\n","\toutputs = np.zeros((num_examples, output_width, output_height, filter_out_channels))\n","\n","\tinputs = np.pad(inputs, ((0, 0), (padX, padX), (padY, padY), (0, 0)), 'constant')\n","\n","\tfor i in range(output_height):\n","\t\tfor j in range(output_width):\n","\t\t\toutputs[:, i, j, :] = tf.tensordot(inputs[:, i:i+5, i:i+5, :], filters, ([1,2,3], [0, 1, 2]))\n","\t\n","\treturn outputs\n","\n","filters_1 = tf.Variable(tf.random.truncated_normal([5,5,3,16], stddev=.1, dtype=tf.double))\n","my_conv = conv2d(inputs, filters_1, [1, 1, 1, 1], padding = \"SAME\")\n","conv = tf.nn.conv2d(inputs, filters_1, strides=[1, 1, 1, 1], padding=\"SAME\")\n","print(np.sum(conv - my_conv))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"Neil_Vignesh_tensorflow_intro.ipynb","provenance":[],"toc_visible":true},"interpreter":{"hash":"3157eb404c51392027cd415cc7e8066da7110d81f6f8d383c11b8332ef0f0733"},"kernelspec":{"display_name":"Python 3.7.0 64-bit ('.virtenv': venv)","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.10"}},"nbformat":4,"nbformat_minor":2}

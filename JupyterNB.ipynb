{"cells":[{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["c:\\Users\\vpand\\Documents\\College\\Fall 2021\\CNN-You-See-What-I-See\\tcav\n"]},{"name":"stderr","output_type":"stream","text":["Cloning into 'tcav'...\n","'ls' is not recognized as an internal or external command,\n","operable program or batch file.\n"]}],"source":["# Clone the entire repo.\n","!git clone https://github.com/tensorflow/tcav.git tcav\n","%cd tcav\n","!dir"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["tf.Tensor(\n","[[1. 0.]\n"," [1. 0.]\n"," [1. 0.]\n"," ...\n"," [1. 0.]\n"," [1. 0.]\n"," [0. 1.]], shape=(10000, 2), dtype=float32)\n"]}],"source":["unpickled_file = unpickle(r\"C:\\Users\\vpand\\Documents\\College\\Fall 2021\\CS1470 HW\\hw2-cnn-vpandiarajan20\\data\\train\")\n","inputs = unpickled_file[b'data']\n","labels = unpickled_file[b'labels']\n","labels_coords = np.nonzero((labels == 3) | (labels == 5))\n","labels = np.reshape(labels, 50000, 1)\n","labels = labels[labels_coords];\n","inputs = inputs[labels_coords] / 255;\n","inputs = tf.reshape(inputs, (-1, 3, 32 ,32))\n","inputs = tf.transpose(inputs, perm=[0,2,3,1])\n","labels = np.where(labels == 3, 0, 1)\n","o_hot_labels = tf.one_hot(labels, 2)\n","print(o_hot_labels)\n"]},{"cell_type":"code","execution_count":27,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["(0,)\n","[]\n"]}],"source":["unpickled_file = unpickle(r\"C:\\Users\\vpand\\Documents\\College\\Fall 2021\\CS1470 HW\\hw2-cnn-vpandiarajan20\\data\\train\")\n","inputs = unpickled_file[b'data']\n","labels = unpickled_file[b'labels']\n","\t\n","rowsf= np.nonzero(labels != 3)\n","rowss= np.nonzero(labels != 5)\n","rows_del = np.concatenate([rowsf, rowss])\n","\n","filtered_inputs = np.delete(inputs, rows_del, axis = 0)\n","filtered_labels = np.delete(labels, rows_del, axis = 0)\n","print(np.shape(filtered_labels))\n","print(filtered_labels)\n","\t# norm_inputs = filtered_inputs.astype(np.float32) / 255\n","\n","\t# # shape (num_examples, 32, 32, 3)\n","\t# reshape_inputs = tf.reshape(norm_inputs, (-1, 3, 32 ,32))\n","\t# t_inputs = reshape_inputs.transpose(inputs, perm=[0,2,3,1])\n","\n","\t# binary_labels = np.where(filtered_labels == first_class, 0, 1)\n","\t# rh_labels = tf.one_hot(binary_labels, 2) #make into tensor?\n","\n","\t# return t_inputs, rh_labels"]},{"cell_type":"code","execution_count":28,"metadata":{},"outputs":[],"source":["unpickled_file = unpickle(r\"C:\\Users\\vpand\\Documents\\College\\Fall 2021\\CS1470 HW\\hw2-cnn-vpandiarajan20\\data\\train\")\n","inputs = unpickled_file[b'data']\n","labels = unpickled_file[b'labels']\n","labels_coords = np.nonzero((labels == 3) | (labels == 5))\n","labels = labels[labels_coords];\n","inputs = inputs[labels_coords] / 255;\n","inputs = tf.reshape(inputs, (-1, 3, 32 ,32))\n","inputs = tf.transpose(inputs, perm=[0,2,3,1])\n","labels = np.where(labels == 3, 0, 1)\n","o_hot_labels = tf.one_hot(labels, 2)\n"]},{"cell_type":"code","execution_count":57,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["tf.Tensor([64 32 32  3], shape=(4,), dtype=int32)\n","tf.Tensor([64 28 28 16], shape=(4,), dtype=int32)\n","tf.Tensor([64 14 14 16], shape=(4,), dtype=int32)\n","tf.Tensor([64  7  7 20], shape=(4,), dtype=int32)\n","tf.Tensor([64  4  4 20], shape=(4,), dtype=int32)\n","tf.Tensor([64  4  4 20], shape=(4,), dtype=int32)\n","tf.Tensor([64  4  4 20], shape=(4,), dtype=int32)\n"]}],"source":["inputs = inputs[0:64]\n","print(tf.shape(inputs))\n","filters_1 = tf.Variable(tf.random.truncated_normal([5,5,3,16], stddev=.1, dtype=tf.double))\n","conv_1 = tf.nn.conv2d(inputs, filters_1, strides=[1, 1, 1, 1], padding='VALID')\n","print(tf.shape(conv_1))\n","mean_1, variance_1 = tf.nn.moments(conv_1, [0,1,2])\n","batch_normalize_1 = tf.nn.batch_normalization(conv_1, mean_1, variance_1, None, None, variance_epsilon=1e-5)\n","post_relu_1 = tf.nn.relu(batch_normalize_1)\n","post_max_pooling_1 = tf.nn.max_pool(post_relu_1, ksize=[1,3,3,1], strides=[1,2,2,1], padding='SAME')\n","print(tf.shape(post_max_pooling_1))\n","\n","filters_2 = tf.Variable(tf.random.truncated_normal([5,5,16,20], stddev=.1, dtype=tf.double))        \n","conv_2 = tf.nn.conv2d(post_max_pooling_1, filters_2, strides=[1, 2, 2, 1], padding='SAME')\n","print(tf.shape(conv_2))\n","mean_2, variance_2 = tf.nn.moments(conv_2, [0,1,2])\n","batch_normalize_2 = tf.nn.batch_normalization(conv_2, mean_2, variance_2, None, None, variance_epsilon=1e-5)\n","post_relu_2 = tf.nn.relu(batch_normalize_2)\n","post_max_pooling_2 = tf.nn.max_pool(post_relu_2, ksize=[1,2,2,1], strides=[1,2,2,1], padding=\"SAME\")\n","print(tf.shape(post_max_pooling_2))\n","\n","filters_3 = tf.Variable(tf.random.truncated_normal([3,3,20,20], stddev=.1, dtype=tf.double))\n","conv_3 = tf.nn.conv2d(post_max_pooling_2, filters_3, strides=[1,1,1,1], padding=\"SAME\")\n","print(tf.shape(conv_3))\n","mean_3, variance_3 = tf.nn.moments(conv_3, [0,1,2])\n","batch_normalize_3 = tf.nn.batch_normalization(conv_3, mean_3, variance_3, None, None, variance_epsilon=1e-5)\n","post_relu_3 = tf.nn.relu(batch_normalize_3)\n","print(tf.shape(post_relu_3))\n","\n"]},{"cell_type":"code","execution_count":38,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["tf.Tensor(8555, shape=(), dtype=int32)\n"]}],"source":["rank_3_tensor = tf.constant([\n","  [[0, 1, 2, 3, 4],\n","   [5, 6, 7, 8, 9]],\n","  [[10, 11, 12, 13, 14],\n","   [15, 16, 17, 18, 19]],\n","  [[20, 21, 22, 23, 24],\n","   [25, 26, 27, 28, 29]],])\n","\n","print(tf.tensordot(rank_3_tensor, rank_3_tensor, axes = 3))"]},{"cell_type":"code","execution_count":55,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["[[[75. 75. 75. ... 75. 75. 75.]\n","  [ 0.  0.  0. ...  0.  0.  0.]\n","  [ 0.  0.  0. ...  0.  0.  0.]\n","  ...\n","  [ 0.  0.  0. ...  0.  0.  0.]\n","  [ 0.  0.  0. ...  0.  0.  0.]\n","  [ 0.  0.  0. ...  0.  0.  0.]]\n","\n"," [[ 0.  0.  0. ...  0.  0.  0.]\n","  [ 0.  0.  0. ...  0.  0.  0.]\n","  [ 0.  0.  0. ...  0.  0.  0.]\n","  ...\n","  [ 0.  0.  0. ...  0.  0.  0.]\n","  [ 0.  0.  0. ...  0.  0.  0.]\n","  [ 0.  0.  0. ...  0.  0.  0.]]\n","\n"," [[ 0.  0.  0. ...  0.  0.  0.]\n","  [ 0.  0.  0. ...  0.  0.  0.]\n","  [ 0.  0.  0. ...  0.  0.  0.]\n","  ...\n","  [ 0.  0.  0. ...  0.  0.  0.]\n","  [ 0.  0.  0. ...  0.  0.  0.]\n","  [ 0.  0.  0. ...  0.  0.  0.]]\n","\n"," ...\n","\n"," [[ 0.  0.  0. ...  0.  0.  0.]\n","  [ 0.  0.  0. ...  0.  0.  0.]\n","  [ 0.  0.  0. ...  0.  0.  0.]\n","  ...\n","  [ 0.  0.  0. ...  0.  0.  0.]\n","  [ 0.  0.  0. ...  0.  0.  0.]\n","  [ 0.  0.  0. ...  0.  0.  0.]]\n","\n"," [[ 0.  0.  0. ...  0.  0.  0.]\n","  [ 0.  0.  0. ...  0.  0.  0.]\n","  [ 0.  0.  0. ...  0.  0.  0.]\n","  ...\n","  [ 0.  0.  0. ...  0.  0.  0.]\n","  [ 0.  0.  0. ...  0.  0.  0.]\n","  [ 0.  0.  0. ...  0.  0.  0.]]\n","\n"," [[ 0.  0.  0. ...  0.  0.  0.]\n","  [ 0.  0.  0. ...  0.  0.  0.]\n","  [ 0.  0.  0. ...  0.  0.  0.]\n","  ...\n","  [ 0.  0.  0. ...  0.  0.  0.]\n","  [ 0.  0.  0. ...  0.  0.  0.]\n","  [ 0.  0.  0. ...  0.  0.  0.]]]\n"]}],"source":["inputImage = tf.ones([64, 5, 5, 3])\n","inputFilters = tf.ones([5, 5, 3, 16])\n","# print(tf.tensordot(inputImage, inputFilters, ([1,2,3], [0, 1, 2])))\n","outputs = np.zeros((64, 32, 32, 16))\n","tensorOut = tf.tensordot(inputImage, inputFilters, ([1,2,3], [0, 1, 2]))\n","outputs[:, 0, 0, :] = tensorOut\n","print(outputs[0, :, :, :])"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":75,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["[64 32 32  3]\n","[ 5  5  3 16]\n","16\n","<class 'int'>\n","2241.5220263007527\n"]}],"source":["import math\n","def conv2d(inputs, filters, strides, padding):\n","\t\"\"\"\n","\tPerforms 2D convolution given 4D inputs and filter Tensors.\n","\t:param inputs: tensor with shape [num_examples, in_height, in_width, in_channels]\n","\t:param filters: tensor with shape [filter_height, filter_width, in_channels, out_channels]\n","\t:param strides: MUST BE [1, 1, 1, 1] - list of strides, with each stride corresponding to each dimension in input\n","\t:param padding: either \"SAME\" or \"VALID\", capitalization matters\n","\t:return: outputs, NumPy array or Tensor with shape [num_examples, output_height, output_width, output_channels]\n","\t\"\"\"\n","\tinputs_shapes = tf.shape(inputs)\n","\tinputs_shapes = np.array(inputs_shapes)\n","\tprint(inputs_shapes)\n","\n","\tnum_examples = inputs_shapes[0]\n","\tin_height = inputs_shapes[1]\n","\tin_width = inputs_shapes[2]\n","\tinput_in_channels = inputs_shapes[3]\n","\t\n","\tfilter_shapes = tf.shape(filters)\n","\tfilter_shapes = np.array(filter_shapes)\n","\tprint(np.array(filter_shapes))\n","\t\n","\n","\tfilter_height = filter_shapes[0]\n","\tfilter_width = filter_shapes[1]\n","\tfilter_in_channels = filter_shapes[2]\n","\tfilter_out_channels = filter_shapes[3]\n","\n","\tprint(filter_out_channels)\n","\n","\tstrides = np.array(strides)\n","\n","\tnum_examples_stride = strides[0]\n","\tstrideY = strides[1]\n","\tstrideX = strides[2]\n","\tchannels_stride = strides[3]\n","\n","\tassert input_in_channels == filter_in_channels, \"input in channels are not equal to filter in channels\"\n","\n","\t# Cleaning padding input\n","\tif padding == \"SAME\":\n","\t\tpadX = math.floor((filter_height-1)/2)\n","\t\tpadY = math.floor((filter_height-1)/2)\n","\telse:\n","\t\tpadX = 0\n","\t\tpadY = 0\n","\t# Calculate output dimensions\n","\toutput_height = math.floor(((in_height + 2*padY - filter_height) / strideY + 1))\n","\toutput_width = math.floor(((in_width + 2*padX - filter_width) / strideX + 1))\n","\tprint(type(output_height))\n","\toutputs = np.zeros((num_examples, output_width, output_height, filter_out_channels))\n","\n","\tinputs = np.pad(inputs, ((0, 0), (padX, padX), (padY, padY), (0, 0)), 'constant')\n","\n","\tfor i in range(output_height):\n","\t\tfor j in range(output_width):\n","\t\t\toutputs[:, i, j, :] = tf.tensordot(inputs[:, i:i+5, i:i+5, :], filters, ([1,2,3], [0, 1, 2]))\n","\t\n","\treturn outputs\n","\n","filters_1 = tf.Variable(tf.random.truncated_normal([5,5,3,16], stddev=.1, dtype=tf.double))\n","my_conv = conv2d(inputs, filters_1, [1, 1, 1, 1], padding = \"SAME\")\n","conv = tf.nn.conv2d(inputs, filters_1, strides=[1, 1, 1, 1], padding=\"SAME\")\n","print(np.sum(conv - my_conv))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"Neil_Vignesh_tensorflow_intro.ipynb","provenance":[],"toc_visible":true},"interpreter":{"hash":"3157eb404c51392027cd415cc7e8066da7110d81f6f8d383c11b8332ef0f0733"},"kernelspec":{"display_name":"Python 3.7.0 64-bit ('.virtenv': venv)","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.10"}},"nbformat":4,"nbformat_minor":2}
